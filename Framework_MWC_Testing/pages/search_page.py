# pages/search_page.py
import unicodedata
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC


class MWCSearchPage:
    """Trang t√¨m ki·∫øm s·∫£n ph·∫©m tr√™n website MWC."""

    URL = "https://mwc.com.vn/"
    SEARCH_BOX = (By.XPATH, "(//input[@placeholder='T√¨m ki·∫øm'])[1]")
    FIRST_RESULT = (By.XPATH, "/html/body/div[1]/div/section[1]/div/section/div/div/div/div[1]/div[2]/div/div[7]/div/a/div/p[1]")
    PRODUCT_TITLES = (By.CLASS_NAME, "product-grid-title")

    def __init__(self, driver, timeout: int = 12):
        self.driver = driver
        self.wait = WebDriverWait(driver, timeout)

    # ==============================================================
    # üîπ H√†m chu·∫©n h√≥a: chuy·ªÉn ti·∫øng Vi·ªát c√≥ d·∫•u ‚Üí kh√¥ng d·∫•u
    # ==============================================================
    def normalize_text(self, text: str) -> str:
        """X√≥a d·∫•u ti·∫øng Vi·ªát v√† vi·∫øt th∆∞·ªùng ƒë·ªÉ so s√°nh kh√¥ng ph√¢n bi·ªát d·∫•u."""
        if not text:
            return ""
        text = unicodedata.normalize('NFD', text)
        text = text.encode('ascii', 'ignore').decode('utf-8')
        return text.lower().strip()

    # ==============================================================
    # üîπ C√°c h√†nh ƒë·ªông trang t√¨m ki·∫øm
    # ==============================================================
    def open(self):
        """M·ªü trang ch·ªß MWC."""
        self.driver.get(self.URL)

    def search(self, keyword: str):
        """Nh·∫≠p t·ª´ kh√≥a v√†o √¥ t√¨m ki·∫øm v√† nh·∫•n Enter."""
        box = self.wait.until(EC.presence_of_element_located(self.SEARCH_BOX))
        box.clear()
        box.send_keys(keyword)
        box.submit()

    def get_first_result_text(self) -> str:
        """L·∫•y n·ªôi dung s·∫£n ph·∫©m ƒë·∫ßu ti√™n (theo XPath c·ªë ƒë·ªãnh)."""
        try:
            el = self.wait.until(EC.presence_of_element_located(self.FIRST_RESULT))
            return (el.text or "").strip()
        except Exception:
            return ""

    def get_all_titles(self):
        """L·∫•y t·∫•t c·∫£ ti√™u ƒë·ªÅ s·∫£n ph·∫©m tr√™n trang."""
        try:
            self.wait.until(EC.presence_of_all_elements_located(self.PRODUCT_TITLES))
            elements = self.driver.find_elements(*self.PRODUCT_TITLES)
            return [el.text.strip() for el in elements if el.text.strip()]
        except Exception:
            return []

    # ==============================================================
    # üîπ Ki·ªÉm tra k·∫øt qu·∫£ t√¨m ki·∫øm (Actual = n·ªôi dung th·ª±c t·∫ø)
    # ==============================================================
    def check_keyword(self, keyword: str) -> tuple[bool, str]:
        """
        Ki·ªÉm tra tu·∫ßn t·ª± (c√≥ h·ªó tr·ª£ so kh·ªõp kh√¥ng d·∫•u):
        1Ô∏è‚É£ Ki·ªÉm tra s·∫£n ph·∫©m ƒë·∫ßu ti√™n (XPath).
        2Ô∏è‚É£ N·∫øu kh√¥ng c√≥ ho·∫∑c kh√¥ng ch·ª©a ‚Üí ki·ªÉm tra to√†n trang.
        3Ô∏è‚É£ N·∫øu kh√¥ng c√≥ s·∫£n ph·∫©m n√†o ‚Üí ghi r√µ ‚ÄúKh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m.‚Äù
        Tr·∫£ v·ªÅ (bool, actual_text)
        """
        keyword_norm = self.normalize_text(keyword)

        # --- B∆∞·ªõc 1: Ki·ªÉm tra s·∫£n ph·∫©m ƒë·∫ßu ti√™n ---
        first_text = self.get_first_result_text()
        first_norm = self.normalize_text(first_text)

        if first_text and keyword_norm in first_norm:
            # ‚úÖ N·∫øu s·∫£n ph·∫©m ƒë·∫ßu ti√™n ch·ª©a t·ª´ kh√≥a
            return True, first_text  # Ghi n·ªôi dung th·∫≠t l√†m Actual

        # --- B∆∞·ªõc 2: Ki·ªÉm tra to√†n trang ---
        all_titles = self.get_all_titles()
        if all_titles:
            for title in all_titles:
                if keyword_norm in self.normalize_text(title):
                    return True, title  # Ghi s·∫£n ph·∫©m t√¨m th·∫•y th·∫≠t
            return False, "Kh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m"

        # --- B∆∞·ªõc 3: Kh√¥ng c√≥ s·∫£n ph·∫©m n√†o ---
        return False, "Kh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m"
